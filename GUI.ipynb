{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy\n",
    "import time\n",
    "import cv2\n",
    "from tkinter import *\n",
    "from tkinter import simpledialog\n",
    "# for beep\n",
    "# from pygame import mixer\n",
    "# import time\n",
    "import xlwt;\n",
    "from datetime import datetime;\n",
    "from xlrd import open_workbook;\n",
    "from xlwt import Workbook;\n",
    "from xlutils.copy import copy\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\vivek\\Anaconda3\\lib\\site-packages\\h5py\\__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n",
      "C:\\Users\\vivek\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "C:\\Users\\vivek\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "C:\\Users\\vivek\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "C:\\Users\\vivek\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "C:\\Users\\vivek\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "C:\\Users\\vivek\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "C:\\Users\\vivek\\Anaconda3\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "C:\\Users\\vivek\\Anaconda3\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "C:\\Users\\vivek\\Anaconda3\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "C:\\Users\\vivek\\Anaconda3\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "C:\\Users\\vivek\\Anaconda3\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "C:\\Users\\vivek\\Anaconda3\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import cv2\n",
    "import face_recognition\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from collections import defaultdict\n",
    "from imutils.video import VideoStream\n",
    "from keras.models import Sequential,model_from_json,Model\n",
    "from scipy.ndimage import imread\n",
    "from scipy.misc import imresize, imsave\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "from playsound import playsound\n",
    "IMG_SIZE = 24"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def hel():\n",
    "    help(cv2)\n",
    "\n",
    "def Contri():\n",
    "    messagebox.showinfo(\"Contributors\",\"\\n1.Kartik Tyagi\\n2. Naman Tyagi \\n3. Abhay Mudgal \\n\")\n",
    "\n",
    "def anotherWin():\n",
    "    messagebox.showinfo(\"About\",'Smart Attendance System v1.0\\n Made Using\\n-OpenCV\\n-Numpy\\n-Tkinter\\n In Python 3')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def output(filename, sheet,num, name, present):\n",
    "    my_file = Path('firebase/attendance_files/'+filename+str(datetime.now().date())+'.xls');\n",
    "    if my_file.is_file():\n",
    "        rb = open_workbook('firebase/attendance_files/'+filename+str(datetime.now().date())+'.xls');\n",
    "        book = copy(rb);\n",
    "        sh = book.get_sheet(0)\n",
    "        # file exists\n",
    "    else:\n",
    "        book = xlwt.Workbook()\n",
    "        sh = book.add_sheet(sheet)\n",
    "    style0 = xlwt.easyxf('font: name Times New Roman, color-index red, bold on',\n",
    "                         num_format_str='#,##0.00')\n",
    "    style1 = xlwt.easyxf(num_format_str='D-MMM-YY')\n",
    "\n",
    "    #variables = [x, y, z]\n",
    "    #x_desc = 'Display'\n",
    "    #y_desc = 'Dominance'\n",
    "    #z_desc = 'Test'\n",
    "    #desc = [x_desc, y_desc, z_desc]\n",
    "    sh.write(0,0,datetime.now().date(),style1);\n",
    "\n",
    "\n",
    "    col1_name = 'Name'\n",
    "    col2_name = 'Present'\n",
    "\n",
    "\n",
    "    sh.write(1,0,col1_name,style0);\n",
    "    sh.write(1, 1, col2_name,style0);\n",
    "\n",
    "    sh.write(num+1,0,name);\n",
    "    sh.write(num+1, 1, present);\n",
    "\n",
    "    fullname=filename+str(datetime.now().date())+'.xls';\n",
    "    book.save('firebase/attendance_files/'+fullname)\n",
    "    #return fullname;\n",
    "\n",
    "def predict(img, model):\n",
    "    img = Image.fromarray(img, 'RGB').convert('L')\n",
    "    img = imresize(img, (IMG_SIZE,IMG_SIZE)).astype('float32')\n",
    "    img /= 255\n",
    "    #plt.imshow(img,cmap = plt.cm.gray)\n",
    "    img = img.reshape(1,IMG_SIZE,IMG_SIZE,1)\n",
    "    \n",
    "    prediction = model.predict(img)\n",
    "    if prediction < 0.15:\n",
    "        prediction = 'closed'\n",
    "    else:\n",
    "        prediction = 'open'\n",
    "        \n",
    "    return prediction\n",
    "\n",
    "def load_model():\n",
    "    json_file = open('weights/model.json', 'r')\n",
    "    loaded_model_json = json_file.read()\n",
    "    json_file.close()\n",
    "    loaded_model = model_from_json(loaded_model_json)\n",
    "    # load weights into new model\n",
    "    loaded_model.load_weights(\"weights/model.h5\")\n",
    "    return loaded_model\n",
    "    \n",
    "def init():\n",
    "    # face_cascPath = 'haarcascade_frontalface_alt.xml'\n",
    "    face_cascPath = 'lbpcascade_frontalface.xml'\n",
    "\n",
    "    open_eye_cascPath = 'haarcascade_eye_tree_eyeglasses.xml'\n",
    "    left_eye_cascPath = 'haarcascade_lefteye_2splits.xml'\n",
    "    right_eye_cascPath ='haarcascade_righteye_2splits.xml'\n",
    "    dataset = 'faces'\n",
    "\n",
    "    face_detector = cv2.CascadeClassifier(face_cascPath)\n",
    "    open_eyes_detector = cv2.CascadeClassifier(open_eye_cascPath)\n",
    "    left_eye_detector = cv2.CascadeClassifier(left_eye_cascPath)\n",
    "    right_eye_detector = cv2.CascadeClassifier(right_eye_cascPath)\n",
    "\n",
    "    print(\"[LOG] Opening webcam ...\")\n",
    "    video_capture = VideoStream(src=0).start()\n",
    "\n",
    "    model = load_model()\n",
    "\n",
    "    print(\"[LOG] Collecting images ...\")\n",
    "    images = []\n",
    "    for direc, _, files in tqdm(os.walk(dataset)):\n",
    "        for file in files:\n",
    "            if file.endswith(\"jpg\"):\n",
    "                images.append(os.path.join(direc,file))\n",
    "    return (model,face_detector, open_eyes_detector, left_eye_detector,right_eye_detector, video_capture, images) \n",
    "\n",
    "def process_and_encode(images):\n",
    "    # initialize the list of known encodings and known names\n",
    "    known_encodings = []\n",
    "    known_names = []\n",
    "    print(\"[LOG] Encoding faces ...\")\n",
    "\n",
    "    for image_path in tqdm(images):\n",
    "        # Load image\n",
    "        image = cv2.imread(image_path)\n",
    "        # Convert it from BGR to RGB\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "     \n",
    "        # detect face in the image and get its location (square boxes coordinates)\n",
    "        boxes = face_recognition.face_locations(image, model='hog')\n",
    "        # Encode the face into a 128-d embeddings vector\n",
    "        encoding = face_recognition.face_encodings(image, boxes)\n",
    "        # the person's name is the name of the folder where the image comes from\n",
    "        name = image_path.split(os.path.sep)[-1]\n",
    "        name = name[0:len(name)-4].split('_')[1]\n",
    "\n",
    "        if len(encoding) > 0 : \n",
    "            known_encodings.append(encoding[0])\n",
    "            known_names.append(name)\n",
    "\n",
    "    return {\"encodings\": known_encodings, \"names\": known_names}\n",
    "\n",
    "def isBlinking(history, maxFrames):\n",
    "    \"\"\" @history: A string containing the history of eyes status \n",
    "         where a '1' means that the eyes were closed and '0' open.\n",
    "        @maxFrames: The maximal number of successive frames where an eye is closed \"\"\"\n",
    "    for i in range(maxFrames):\n",
    "        pattern = '1' + '0'*(i+1) + '1'\n",
    "        if pattern in history:\n",
    "            return True\n",
    "    return False\n",
    "\n",
    "def detect_and_display(model, video_capture, face_detector, open_eyes_detector, left_eye_detector, right_eye_detector, data, eyes_detected):\n",
    "        frame = video_capture.read()\n",
    "        # resize the frame\n",
    "        frame = cv2.resize(frame, (600, 500), fx=0.6, fy=0.6)\n",
    "\n",
    "        gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "        rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "        \n",
    "        # Detect faces\n",
    "        faces = face_detector.detectMultiScale(\n",
    "            gray,\n",
    "            scaleFactor=1.2,\n",
    "            minNeighbors=5,\n",
    "            minSize=(50, 50),\n",
    "            flags=cv2.CASCADE_SCALE_IMAGE\n",
    "        )\n",
    "\n",
    "        # for each detected face\n",
    "        for (x,y,w,h) in faces:\n",
    "            # print(x,y,w,h)\n",
    "            \n",
    "            # Encode the face into a 128-d embeddings vector\n",
    "            encoding = face_recognition.face_encodings(rgb, [(y, x+w, y+h, x)])[0]\n",
    "            \n",
    "            # Compare the vector with all known faces encodings\n",
    "            matches = face_recognition.compare_faces(data[\"encodings\"], encoding)\n",
    "\n",
    "            # For now we don't know the person name\n",
    "            name = \"Unknown\"\n",
    "\n",
    "            # If there is at least one match:\n",
    "            if True in matches:\n",
    "                matchedIdxs = [i for (i, b) in enumerate(matches) if b]\n",
    "                counts = {}\n",
    "                for i in matchedIdxs:\n",
    "                    name = data[\"names\"][i]\n",
    "                    counts[name] = counts.get(name, 0) + 1\n",
    "\n",
    "                # determine the recognized face with the largest number of votes\n",
    "                name = max(counts, key=counts.get)\n",
    "\n",
    "            face = frame[y:y+h,x:x+w]\n",
    "            gray_face = gray[y:y+h,x:x+w]\n",
    "            cv2.rectangle(frame, (x, y), (x+w, y+h), (0, 255, 0), 2)\n",
    "            eyes = []\n",
    "            \n",
    "            # Eyes detection\n",
    "            # check first if eyes are open (with glasses taking into account)\n",
    "            open_eyes_glasses = open_eyes_detector.detectMultiScale(\n",
    "                gray_face,\n",
    "                scaleFactor=1.1,\n",
    "                minNeighbors=5,\n",
    "                minSize=(30, 30),\n",
    "                flags = cv2.CASCADE_SCALE_IMAGE\n",
    "            )\n",
    "            # if open_eyes_glasses detect eyes then they are open \n",
    "            if len(open_eyes_glasses) == 2:\n",
    "                eyes_detected[name]+='1'\n",
    "                for (ex,ey,ew,eh) in open_eyes_glasses:\n",
    "                    cv2.rectangle(face,(ex,ey),(ex+ew,ey+eh),(0,255,0),2)\n",
    "            \n",
    "            # otherwise try detecting eyes using left and right_eye_detector\n",
    "            # which can detect open and closed eyes                \n",
    "            else:\n",
    "                # separate the face into left and right sides\n",
    "                left_face = frame[y:y+h, x+int(w/2):x+w]\n",
    "                left_face_gray = gray[y:y+h, x+int(w/2):x+w]\n",
    "\n",
    "                right_face = frame[y:y+h, x:x+int(w/2)]\n",
    "                right_face_gray = gray[y:y+h, x:x+int(w/2)]\n",
    "\n",
    "                # Detect the left eye\n",
    "                left_eye = left_eye_detector.detectMultiScale(\n",
    "                    left_face_gray,\n",
    "                    scaleFactor=1.1,\n",
    "                    minNeighbors=5,\n",
    "                    minSize=(30, 30),\n",
    "                    flags = cv2.CASCADE_SCALE_IMAGE\n",
    "                )\n",
    "\n",
    "                # Detect the right eye\n",
    "                right_eye = right_eye_detector.detectMultiScale(\n",
    "                    right_face_gray,\n",
    "                    scaleFactor=1.1,\n",
    "                    minNeighbors=5,\n",
    "                    minSize=(30, 30),\n",
    "                    flags = cv2.CASCADE_SCALE_IMAGE\n",
    "                )\n",
    "\n",
    "                eye_status = '1' # we suppose the eyes are open\n",
    "\n",
    "                # For each eye check wether the eye is closed.\n",
    "                # If one is closed we conclude the eyes are closed\n",
    "                for (ex,ey,ew,eh) in right_eye:\n",
    "                    color = (0,255,0)\n",
    "                    pred = predict(right_face[ey:ey+eh,ex:ex+ew],model)\n",
    "                    if pred == 'closed':\n",
    "                        eye_status='0'\n",
    "                        color = (0,0,255)\n",
    "                    cv2.rectangle(right_face,(ex,ey),(ex+ew,ey+eh),color,2)\n",
    "                    \n",
    "                for (ex,ey,ew,eh) in left_eye:\n",
    "                    color = (0,255,0)\n",
    "                    pred = predict(left_face[ey:ey+eh,ex:ex+ew],model)\n",
    "                    if pred == 'closed':\n",
    "                        eye_status='0'\n",
    "                        color = (0,0,255)\n",
    "                    cv2.rectangle(left_face,(ex,ey),(ex+ew,ey+eh),color,2)\n",
    "                eyes_detected[name] += eye_status\n",
    "\n",
    "            # Each time, we check if the person has blinked\n",
    "            # If yes, we display its name\n",
    "            if isBlinking(eyes_detected[name],3):\n",
    "                cv2.rectangle(frame, (x, y), (x+w, y+h), (0, 255, 0), 2)\n",
    "                # Display name\n",
    "                y = y - 15 if y - 15 > 15 else y + 15\n",
    "                cv2.putText(frame, name, (x, y), cv2.FONT_HERSHEY_SIMPLEX,0.75, (0, 255, 0), 2)\n",
    "                output('attendance','class 1',1,name,'yes')\n",
    "\n",
    "        return frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def exitt():\n",
    "    exit()\n",
    "\n",
    "def web():\n",
    "    capture =cv2.VideoCapture(0)\n",
    "    while True:\n",
    "        ret,frame=capture.read()\n",
    "        gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "        cv2.imshow('frame',frame)\n",
    "        if cv2.waitKey(1) & 0xFF ==ord('q'):\n",
    "            break\n",
    "    capture.release()\n",
    "    cv2.destroyAllWindows() \n",
    "\n",
    "def startAttendance():\n",
    "    (model, face_detector, open_eyes_detector,left_eye_detector,right_eye_detector, video_capture, images) = init()\n",
    "    data = process_and_encode(images)\n",
    "    #print(data)\n",
    "    eyes_detected = defaultdict(str)\n",
    "    \n",
    "    while True:\n",
    "        frame = detect_and_display(model, video_capture, face_detector, open_eyes_detector,left_eye_detector,right_eye_detector, data, eyes_detected)\n",
    "        cv2.imshow(\"Face Liveness Detector\", frame)\n",
    "        if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "            break\n",
    "    cv2.destroyAllWindows()\n",
    "    video_capture.stop()\n",
    "\n",
    "def webdet():\n",
    "    capture =cv2.VideoCapture(0)\n",
    "    face_cascade = cv2.CascadeClassifier('lbpcascade_frontalface.xml')\n",
    "    eye_glass = cv2.CascadeClassifier('haarcascade_eye_tree_eyeglasses.xml')\n",
    "\n",
    "\n",
    "    while True:\n",
    "        ret, frame = capture.read()\n",
    "        gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "        faces = face_cascade.detectMultiScale(gray)\n",
    "    \n",
    "\n",
    "        for (x,y,w,h) in faces:\n",
    "            font = cv2.FONT_HERSHEY_COMPLEX\n",
    "            cv2.putText(frame,'Face',(x+w,y+h),font,1,(250,250,250),2,cv2.LINE_AA)\n",
    "            cv2.rectangle(frame,(x,y),(x+w,y+h),(255,0,0),2)\n",
    "            roi_gray = gray[y:y+h, x:x+w]\n",
    "            roi_color = frame[y:y+h, x:x+w]\n",
    "        \n",
    "            eye_g = eye_glass.detectMultiScale(roi_gray)\n",
    "            for (ex,ey,ew,eh) in eye_g:\n",
    "                cv2.rectangle(roi_color,(ex,ey),(ex+ew,ey+eh),(0,255,0),2)\n",
    "\n",
    "       \n",
    "        cv2.imshow('frame',frame)\n",
    "        if cv2.waitKey(1) & 0xff == ord('q'):\n",
    "            break\n",
    "    capture.release()\n",
    "    cv2.destroyAllWindows()\n",
    "\n",
    "def alert():\n",
    "    mixer.init()\n",
    "    alert=mixer.Sound('beep-07.wav')\n",
    "    alert.play()\n",
    "    time.sleep(0.1)\n",
    "    alert.play()   \n",
    "    \n",
    "def data_Add():\n",
    "    sampleNum = 0\n",
    "    user_name = simpledialog.askstring(\"Enter Name\", \"Enter User Name\")\n",
    "    #print(user_name)\n",
    "    \n",
    "    while user_name==\"\":\n",
    "        simpledialog.messagebox.showwarning(\"Error\", \"Name Field cannot be left blank !\")\n",
    "        user_name = simpledialog.askstring(\"user_name\", \"Enter User Name\")\n",
    "    \n",
    "    simpledialog.messagebox.showinfo(\"Ready\", \"Please look at the Webcam.\\nTurn your head a little while capturing.\\nPlease add just one face at a time. \\n Click 'OK' when you're ready.\")\n",
    "    capture =cv2.VideoCapture(0)\n",
    "    face_cascade = cv2.CascadeClassifier('lbpcascade_frontalface.xml')\n",
    "    eye_glass = cv2.CascadeClassifier('haarcascade_eye_tree_eyeglasses.xml')\n",
    "\n",
    "    while True:\n",
    "        ret, frame = capture.read()\n",
    "        gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "        faces = face_cascade.detectMultiScale(gray)\n",
    "\n",
    "\n",
    "        for (x,y,w,h) in faces:\n",
    "            font = cv2.FONT_HERSHEY_COMPLEX\n",
    "            cv2.putText(frame,'Face-'+str(sampleNum),(x+w,y+h),font,1,(250,250,250),2,cv2.LINE_AA)\n",
    "            sampleNum = sampleNum + 1  #increment sample num till 21\n",
    "            roi_gray = gray[y:y+h, x:x+w]\n",
    "            roi_color = frame[y:y+h, x:x+w]\n",
    "            face_path = 'faces/User_'+user_name+'_'+str(sampleNum)+'.jpg'\n",
    "            cv2.imwrite(str(face_path), roi_color) \n",
    "            cv2.rectangle(frame,(x,y),(x+w,y+h),(255,0,0),2)\n",
    "            cv2.waitKey(100)\n",
    "\n",
    "        cv2.imshow('faces', frame)  #show image while capturing\n",
    "        cv2.waitKey(7000)\n",
    "        if(sampleNum > 3 or (cv2.waitKey(1) & 0xff == ord('q'))): #4 sample is collected\n",
    "            break   \n",
    "    capture.release()\n",
    "    playsound('sound.mp3')\n",
    "    cv2.destroyAllWindows()\n",
    "    \n",
    "def attend():\n",
    "    os.startfile(os.getcwd()+\"/firebase/attendance_files/attendance\"+str(datetime.now().date())+'.xls')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "root=Tk()\n",
    "root.geometry('500x570')\n",
    "frame = Frame(root, relief=RIDGE, borderwidth=2)\n",
    "frame.pack(fill=BOTH,expand=1)\n",
    "root.title('Smart Cam')\n",
    "frame.config(background='light blue')\n",
    "label = Label(frame, text=\"Smart Attendance App\",bg='light blue',font=('Times 35 bold'))\n",
    "label.pack(side=TOP)\n",
    "\n",
    "background_image = PhotoImage(file=\"demo.png\")\n",
    "background_image = background_image.subsample(1, 1)\n",
    "background = Label( image=background_image, bd=0)#made changes Label(root,)\n",
    "background.pack(side=TOP)\n",
    "\n",
    "menu = Menu(root)\n",
    "root.config(menu=menu)\n",
    "\n",
    "subm1 = Menu(menu)\n",
    "menu.add_cascade(label=\"Tools\",menu=subm1)\n",
    "subm1.add_command(label=\"Open CV Docs\",command=hel)\n",
    "\n",
    "subm2 = Menu(menu)\n",
    "menu.add_cascade(label=\"About\",menu=subm2)\n",
    "subm2.add_command(label=\"Driver Cam\",command=anotherWin)\n",
    "subm2.add_command(label=\"Contributors\",command=Contri)\n",
    "\n",
    "\n",
    "but1=Button(background,padx=5,pady=5,width=39,bg='white',fg='black',relief=GROOVE,command=webdet,text='Open Cam',font=('helvetica 15 bold'))\n",
    "but1.place(x=5,y=104)\n",
    "\n",
    "but2=Button(background,padx=5,pady=5,width=39,bg='white',fg='black',relief=GROOVE,command=data_Add,text='Add Person',font=('helvetica 15 bold'))\n",
    "but2.place(x=5,y=176)\n",
    "\n",
    "but3=Button(background,padx=5,pady=5,width=39,bg='white',fg='black',relief=GROOVE,command=startAttendance,text='Start',font=('helvetica 15 bold'))\n",
    "but3.place(x=5,y=250)\n",
    "\n",
    "but4=Button(background,padx=5,pady=5,width=39,bg='white',fg='black',relief=GROOVE,command=attend,text='Attendance Sheet',font=('helvetica 15 bold'))\n",
    "but4.place(x=5,y=323)\n",
    "\n",
    "but5=Button(background,padx=5,pady=5,width=5,bg='white',fg='black',relief=GROOVE,text='EXIT',command=exitt,font=('helvetica 15 bold'))\n",
    "but5.place(x=210,y=400)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LOG] Opening webcam ...\n",
      "WARNING:tensorflow:From C:\\Users\\vivek\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:517: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\vivek\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:4138: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\vivek\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:3976: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\vivek\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:174: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\vivek\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:181: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\vivek\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:186: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2it [00:00, 1382.21it/s]\n",
      "  0%|                                                                                            | 0/8 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LOG] Collecting images ...\n",
      "[LOG] Encoding faces ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 8/8 [00:03<00:00,  2.27it/s]\n",
      "C:\\Users\\vivek\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:39: DeprecationWarning: `imresize` is deprecated!\n",
      "`imresize` is deprecated in SciPy 1.0.0, and will be removed in 1.2.0.\n",
      "Use ``skimage.transform.resize`` instead.\n",
      "Exception in Tkinter callback\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\vivek\\Anaconda3\\lib\\tkinter\\__init__.py\", line 1702, in __call__\n",
      "    return self.func(*args)\n",
      "  File \"<ipython-input-5-17936fd7280d>\", line 106, in attend\n",
      "    os.startfile(os.getcwd()+\"/firebase/attendance_files/attendance\"+str(datetime.now().date())+'.xls')\n",
      "OSError: [WinError 1155] No application is associated with the specified file for this operation: 'C:\\\\Users\\\\vivek\\\\Downloads\\\\Smart Attendance System/firebase/attendance_files/attendance2020-08-07.xls'\n"
     ]
    }
   ],
   "source": [
    "root.mainloop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
